{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from binance.client import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os.path\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil import parser\n",
    "from tqdm import tqdm_notebook \n",
    "from hmmlearn import hmm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "regimes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### API\n",
    "binance_api_key = '25HUOrJu76evPWNCJtSDydExaKtdB6DjyItVW5lTYSzEe2NgAvMsfLfuuX8Ake1m'  \n",
    "binance_api_secret = 'vBaUNet4o7N2qVA3lW84Is6RXFnAt4Q6Dk6qdfiR1VzAOi0vO4Ujq2eCq0qHjCfP'\n",
    "\n",
    "### CONSTANTS\n",
    "binsizes = {\"1m\": 1, \"5m\": 5, \"1h\": 60, \"1d\": 1440}\n",
    "batch_size = 750\n",
    "binance_client = Client(api_key=binance_api_key, api_secret=binance_api_secret)\n",
    "\n",
    "\n",
    "### FUNCTIONS\n",
    "def minutes_of_new_data(symbol, kline_size, data, source):\n",
    "    if len(data) > 0:  old = parser.parse(data[\"timestamp\"].iloc[-1])\n",
    "    elif source == \"binance\": old = datetime.strptime('1 Jan 2017', '%d %b %Y')\n",
    "    if source == \"binance\": new = pd.to_datetime(binance_client.get_klines(symbol=symbol, interval=kline_size)[-1][0], unit='ms')\n",
    "    return old, new\n",
    "\n",
    "def get_all_binance(symbol, kline_size, save = False):\n",
    "    filename = '%s-%s-data.csv' % (symbol, kline_size)\n",
    "    if os.path.isfile(filename): data_df = pd.read_csv(filename)\n",
    "    else: data_df = pd.DataFrame()\n",
    "    oldest_point, newest_point = minutes_of_new_data(symbol, kline_size, data_df, source = \"binance\")\n",
    "    delta_min = (newest_point - oldest_point).total_seconds()/60\n",
    "    available_data = math.ceil(delta_min/binsizes[kline_size])\n",
    "    if oldest_point == datetime.strptime('1 Jan 2017', '%d %b %Y'): print('Downloading all available %s data for %s. Be patient..!' % (kline_size, symbol))\n",
    "    else: print('Downloading %d minutes of new data available for %s, i.e. %d instances of %s data.' % (delta_min, symbol, available_data, kline_size))\n",
    "    klines = binance_client.get_historical_klines(symbol, kline_size, oldest_point.strftime(\"%d %b %Y %H:%M:%S\"), newest_point.strftime(\"%d %b %Y %H:%M:%S\"))\n",
    "    data = pd.DataFrame(klines, columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_av', 'trades', 'tb_base_av', 'tb_quote_av', 'ignore' ])\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "    if len(data_df) > 0:\n",
    "        temp_df = pd.DataFrame(data)\n",
    "        data_df = data_df.append(temp_df)\n",
    "    else: data_df = data\n",
    "    data_df.set_index('timestamp', inplace=True)\n",
    "    if save: data_df.to_csv(filename)\n",
    "    print('All caught up..!')\n",
    "    return data_df\n",
    "\n",
    "def get_return(pre, post):\n",
    "    return (post-pre)/pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading all available 5m data for XLMUSDT. Be patient..!\n"
     ]
    }
   ],
   "source": [
    "data = get_all_binance(\"XLMUSDT\", \"5m\", save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = np.array(data.iloc[:,3].astype(float), np.float)[-279564:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = []\n",
    "temp = []\n",
    "values = []\n",
    "for i in range(0, len(close)):\n",
    "    temp.append(close[i])\n",
    "    if len(temp) == 288:\n",
    "        today = [get_return(temp[0], temp[-1]), mean_squared_error(temp, [sum(temp) / len(temp)] * len(temp))]\n",
    "        values.append(temp[-1])\n",
    "        obs.append(today)\n",
    "        temp = []\n",
    "\n",
    "training = obs[300:900]\n",
    "test = obs[900:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Hidden Markov Model\n",
    "model = hmm.GaussianHMM(n_components = regimes, covariance_type=\"full\", n_iter = 75);\n",
    "\n",
    "# Fitting the model and obtaining predictions\n",
    "model.fit(obs)\n",
    "predictions = model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predictions, 'ro');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=values)\n",
    "df = df.rename(columns={0: \"values\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.relplot(x=range(0, len(predictions)), y=\"values\", data = df, hue=predictions, linewidth = 0, palette=\"Set1\", s = 12);\n",
    "plot.fig.set_size_inches(18,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = df.iloc[300:900, :]\n",
    "training_obs = obs[300:900]\n",
    "model = hmm.GaussianHMM(n_components = regimes, covariance_type=\"full\", n_iter = 75);\n",
    "model.fit(training_obs)\n",
    "training_predictions = model.predict(training_obs)\n",
    "plot = sns.relplot(x=range(0, len(training)), y=\"values\", data = tdf, hue=training_predictions, linewidth = 0, palette=\"Set1\", s = 12);\n",
    "plot.fig.set_size_inches(18,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regime_count = {}\n",
    "regime_returns = {}\n",
    "regime_volatility = {}\n",
    "\n",
    "for i in range(0, regimes):\n",
    "    regime_returns[i] = 0\n",
    "    regime_volatility[i] = 0\n",
    "    regime_count[i] = 0\n",
    "    \n",
    "for i in range(0, len(training_predictions)):\n",
    "    regime_count[training_predictions[i]] += 1\n",
    "    \n",
    "for i in range(0, len(training_obs)):\n",
    "    regime_returns[training_predictions[i]] += training_obs[i][0]\n",
    "    regime_volatility[training_predictions[i]] += training_obs[i][1]\n",
    "\n",
    "for i in range(0, regimes):\n",
    "    regime_returns[i] = regime_returns[i] / regime_count[i]\n",
    "    regime_volatility[i] = regime_volatility[i] / regime_count[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, regimes):\n",
    "    print(\"Regime \" + str(i) + \" return is \" + str(regime_returns[i]))\n",
    "    print(\"Regime \" + str(i) + \" volatility is \" + str(regime_volatility[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = training[:-100]\n",
    "value = 100\n",
    "position = 0\n",
    "history = []\n",
    "positions = []\n",
    "size = len(test)\n",
    "for i in range(0, size):\n",
    "    if i != 0 and position == 1:\n",
    "        value *= (0.999 + test[i][0])\n",
    "    elif i != 0 and position == -1:\n",
    "        value *= (0.999 - test[i][0])\n",
    "    curr.append(test[i])\n",
    "    forecast = model.predict(curr)[-1]\n",
    "    if forecast == 0:\n",
    "        position = 1\n",
    "    elif forecast == 1:\n",
    "        position = -1\n",
    "    elif forecast == 2:\n",
    "        position = 1\n",
    "    elif forecast == 3:\n",
    "        position = 0\n",
    "    history.append(value)\n",
    "    positions.append(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(np.asarray(get_all_binance(\"ETHUSDT\", \"5m\", save = True)['close'], dtype= np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
